{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FytMzmPcyrW-",
    "outputId": "3a5f0a40-9ada-447f-f5cf-81d9e7fe77db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "UY28a_bTzlIN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "ZWjbL_OFvxTw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XbNDDPvEzli8",
    "outputId": "b52c5b11-0aec-4a16-806e-b19baa3630a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "idENkyR1p-2Z"
   },
   "outputs": [],
   "source": [
    "# to store class name\n",
    "classes_dict = {}\n",
    "\n",
    "def create_class_name_dict():\n",
    "    classes_file = '/content/drive/MyDrive/Colab Notebooks/Data/CUB_200_2011/classes.txt'\n",
    "    try:\n",
    "        with open(classes_file, 'r') as file:\n",
    "            lines = file.read().splitlines()\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            class_label = line.split('.')[1]\n",
    "            classes_dict[i] = class_label\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print('File does not exist.\\n')\n",
    "        return None\n",
    "\n",
    "# create class dict\n",
    "create_class_name_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkQinAz0rjzV"
   },
   "source": [
    "### Data Loading and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "f2bd3T0nqgPs"
   },
   "outputs": [],
   "source": [
    "from pyparsing.common import traceback\n",
    "\n",
    "def denormalize(tensor):\n",
    "    tensor = tensor*std + mean\n",
    "    return tensor\n",
    "\n",
    "def show_img(img):\n",
    "    # arrange channels\n",
    "    img = img.numpy().transpose((1,2,0))\n",
    "\n",
    "    # use mean and std values\n",
    "    img = denormalize(img)\n",
    "\n",
    "    # clip values and view image\n",
    "    img = np.clip(img,0,1)\n",
    "    plt.imshow(img)\n",
    "\n",
    "\n",
    "# returns data loader objects, resizing_factor is a size tuple\n",
    "def get_data_loader(img_dir_path, batch_size=64, shuffle=False, transform=None):\n",
    "\n",
    "    # create custom dataset object\n",
    "    dataset = torchvision.datasets.ImageFolder(img_dir_path, transform=transform)\n",
    "\n",
    "    # create dataloader objects\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnXnLRaTQcYM"
   },
   "source": [
    "### Define Custom Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "8T_G80i7Qfun"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, pretrained_model_name, pretrained_model_path, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.pretrained_model_name =  pretrained_model_name\n",
    "        self.pretrained_model_path = pretrained_model_path\n",
    "        self.num_classes = num_classes\n",
    "        self.in_feat = None\n",
    "        self.model = None\n",
    "\n",
    "        # check for GPU availability\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "\n",
    "        # load model architectures without weight\n",
    "        if use_gpu:\n",
    "            self.model = getattr(models, self.pretrained_model_name)().cuda()\n",
    "        else:\n",
    "            self.model = getattr(models, self.pretrained_model_name)()\n",
    "\n",
    "        # load pre-trained weights\n",
    "        self.model.load_state_dict(torch.load(self.pretrained_model_path))\n",
    "\n",
    "        # get input dimension of the fc layer to be replaced and index of the last fc layer\n",
    "        self.in_feat = self.model.classifier[-1].in_features\n",
    "        fc_idx = len(self.model.classifier) - 1\n",
    "\n",
    "        custom_fc = nn.Sequential(nn.Linear(self.in_feat, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(512, self.num_classes),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.LogSoftmax(dim=1))\n",
    "\n",
    "        # add custom fc layers to model\n",
    "        self.model.classifier[fc_idx] = custom_fc\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFfWH34IKJ_l"
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "7oXdbBVCKIYK"
   },
   "outputs": [],
   "source": [
    "def unfreeze_last_n_layers(model, layer_type, n):\n",
    "\n",
    "    # if n == -1 don't unfreeze any layers\n",
    "    if n == -1:\n",
    "        return 0\n",
    "\n",
    "    n = n*2 # since weights and bias are included as separate\n",
    "\n",
    "    # for classifier layer\n",
    "    if layer_type == 'classifier':\n",
    "        total_layers = len(list(model.model.classifier.parameters()))\n",
    "\n",
    "        # invalid n\n",
    "        if n > total_layers:\n",
    "            print(f\"Warning: There are only {total_layers} layers in the model. Cannot unfreeze {n} layers.\")\n",
    "\n",
    "        # if n == 0 unfreeze all layers\n",
    "        elif n == 0:\n",
    "            for param in model.model.classifier.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            for i, param in enumerate(model.model.classifier.parameters()):\n",
    "                if i >= total_layers - n:\n",
    "                    param.requires_grad = True\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "\n",
    "    # conv layers\n",
    "    elif layer_type == 'features':\n",
    "        total_layers = len(list(model.model.features.parameters()))\n",
    "\n",
    "        # invalid n\n",
    "        if n > total_layers:\n",
    "            print(f\"Warning: There are only {total_layers} layers in the model. Cannot unfreeze {n} layers.\")\n",
    "\n",
    "        # if n == 0 unfreeze all layers\n",
    "        elif n == 0:\n",
    "            for param in model.model.features.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            for i, param in enumerate(model.model.features.parameters()):\n",
    "                if i >= total_layers - n:\n",
    "                    param.requires_grad = True\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "# freezes all layers in the model\n",
    "def freeze_all_layers(model):\n",
    "    for param in model.model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "# returns an optimizer dict for the model given the number of layers being trained\n",
    "def get_optimizer_dict(model, features_n, classifier_n, lr = 3e-4):\n",
    "\n",
    "    # list of dictionaries to store parameter values\n",
    "    params_list = []\n",
    "    fc_layer_indices = []\n",
    "    conv_layer_indices = []\n",
    "\n",
    "    # dividing factor\n",
    "    f_fc = 2\n",
    "    f_conv = 3\n",
    "\n",
    "    if classifier_n != -1:\n",
    "        if classifier_n == 0:\n",
    "            named_params = list(name for name, _ in model.model.classifier.named_parameters())\n",
    "            layer_indices = list(set([int(name.split('.')[0]) for name in named_params]))\n",
    "\n",
    "        else:\n",
    "            # get indices of the last 'n' layers in the model\n",
    "            named_params = list(name for name, _ in model.model.classifier.named_parameters())\n",
    "            layer_indices = list(set([int(name.split('.')[0]) for name in named_params[-classifier_n*2:]]))\n",
    "\n",
    "        for i, index_val in enumerate(layer_indices):\n",
    "            params_list.append({'params':model.model.classifier[index_val].parameters(), 'lr': lr*(f_fc**i)})\n",
    "            fc_layer_indices.append((index_val, lr*(f_fc**i)))\n",
    "\n",
    "\n",
    "    if features_n != -1:\n",
    "        if features_n == 0:\n",
    "            features_n = list(name for name, _ in model.model.features.named_parameters())\n",
    "            layer_indices = list(set([int(name.split('.')[0]) for name in named_params]))\n",
    "\n",
    "        else:\n",
    "            # get indices of the last 'n' layers in the model\n",
    "            named_params = list(name for name, _ in model.model.features.named_parameters())\n",
    "            layer_indices = list(set([int(name.split('.')[0]) for name in named_params[-features_n*2:]]))\n",
    "\n",
    "        for i, index_val in enumerate(layer_indices):\n",
    "            params_list.append({'params':model.model.features[index_val].parameters(), 'lr': lr*(f_conv**i)})\n",
    "            conv_layer_indices.append((index_val, lr*(f_conv**i)))\n",
    "\n",
    "    optimizer = Adam(params_list, lr = lr)\n",
    "    return fc_layer_indices, conv_layer_indices, optimizer\n",
    "\n",
    "# plot history\n",
    "def plot_history(history):\n",
    "    train_loss = history['train_loss']\n",
    "    val_loss = history['val_loss']\n",
    "    train_acc = history['train_acc']\n",
    "    val_acc = history['val_acc']\n",
    "\n",
    "    # Plot train_loss vs. val_loss\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(train_loss, label='Train Loss', color='blue')\n",
    "    plt.plot(val_loss, label='Validation Loss', color='red')\n",
    "    plt.title('Training Vs Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot train_acc vs. val_acc\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(train_acc, label='Train Accuracy', color='blue')\n",
    "    plt.plot(val_acc, label='Validation Accuracy', color='red')\n",
    "    plt.title('Training Vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYwRYG32a6zO"
   },
   "source": [
    "### Train and Validation Functions For Single Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "hYwOYD2UbB2A"
   },
   "outputs": [],
   "source": [
    "from pyparsing.core import ParseExpression\n",
    "# training for single epoch\n",
    "def train(model, dataloader, criterion, optimizer, max_batch, device = 'cpu'):\n",
    "\n",
    "    # initalize variables to store loss and acc\n",
    "    tr_epoch_loss = 0.0\n",
    "    tr_epoch_corr = 0\n",
    "    total = 0\n",
    "\n",
    "    # send model to device and set to training model\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for batch_no, (images, labels) in enumerate(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(images)\n",
    "        y_pred_labels = torch.argmax(torch.exp(y_pred), 1)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tr_epoch_loss += loss.item()\n",
    "        total += labels.size(0)\n",
    "        tr_epoch_corr += (y_pred_labels == labels).sum().item()\n",
    "\n",
    "        if max_batch is not None:\n",
    "            if batch_no == max_batch:\n",
    "                break;\n",
    "\n",
    "    # return epoch loss and accuracy\n",
    "    return tr_epoch_loss, tr_epoch_corr/total\n",
    "\n",
    "def validate(model, dataloader, criterion, device = 'cpu'):\n",
    "\n",
    "    # initialize variables to store validation loss and acc\n",
    "    val_loss = 0.0\n",
    "    val_corr = 0\n",
    "    total = 0\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            y_pred = model(images)\n",
    "            y_pred_labels = torch.argmax(torch.exp(y_pred), 1)\n",
    "            loss = criterion(y_pred, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_corr += (y_pred_labels == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # return validation loss and accuracy\n",
    "    return val_loss, val_corr/total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfOAWwB20geX"
   },
   "source": [
    "### Training Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "uG9tOE940xfF"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function can be used to both train and fine-tune the model.\n",
    "unfreeze_n_fc = number of fc layers to unfreeze from last fc layer (0 = all layers, -1 = none)\n",
    "unfreeze_n_conv = number of conv layers to unfreeze from last conv layer (0 = all layers, -1 = none)\n",
    "\n",
    "By controlling these two parameters, the model can be trained in a step-wise manner:\n",
    "1. unfreeze only the fc layers and train the model\n",
    "2. unfreeze only the last two conv layers and train the model\n",
    "3. fine-tuning: unfreeze the last two conv layers and the entire fc block and train the model\n",
    "'''\n",
    "\n",
    "def train_model_layers(model, train_data, validation_data, epochs, criterion,\n",
    "                       max_batch, unfreeze_n_fc, unfreeze_n_conv):\n",
    "\n",
    "    # dict to store training progress\n",
    "    history = {'train_loss': [],\n",
    "               'val_loss': [],\n",
    "               'train_acc':[],\n",
    "               'val_acc':[]\n",
    "               }\n",
    "\n",
    "    # set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # turn off gradients for all layers except the fc layers\n",
    "    freeze_all_layers(model)\n",
    "    unfreeze_last_n_layers(model, 'classifier', unfreeze_n_fc)\n",
    "    unfreeze_last_n_layers(model, 'features', unfreeze_n_conv)\n",
    "    optimizer = get_optimizer_dict(model, unfreeze_n_fc, unfreeze_n_conv)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # variables to store loss and acc values per epoch\n",
    "        tr_epoch_loss = 0\n",
    "        tr_epoch_acc = 0\n",
    "        val_epoch_loss = 0\n",
    "        val_epoch_acc = 0\n",
    "\n",
    "        # train model\n",
    "        tr_epoch_loss, tr_epoch_acc = train(model, train_data, criterion, optimizer, max_batch, device)\n",
    "        history['train_loss'].append(tr_epoch_loss)\n",
    "        history['train_acc'].append(tr_epoch_acc)\n",
    "\n",
    "        # evaluate model\n",
    "        val_epoch_loss, val_epoch_acc = validate(model, validation_data, criterion, device = 'cpu')\n",
    "        history['val_loss'].append(val_epoch_loss)\n",
    "        history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    # return model and history\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "I7DebY3j98Vi"
   },
   "outputs": [],
   "source": [
    "# define parameters that will remain constant\n",
    "num_classes = 200\n",
    "resizing_factor = (224, 224)  # specific to VGG\n",
    "\n",
    "# normalization paramteters for imagenet\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# define transformers\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize(resizing_factor),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomAffine(degrees = 10,\n",
    "                                translate = (0.2, 0.2), shear = 10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize(resizing_factor),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean, std)])\n",
    "\n",
    "# define path to data\n",
    "train_path = '/content/drive/MyDrive/Colab Notebooks/Data/CUB_200_2011/train_test_cropped/train'\n",
    "test_path = '/content/drive/MyDrive/Colab Notebooks/Data/CUB_200_2011/train_test_cropped/test'\n",
    "train_loader = get_data_loader(train_path, 64, True, train_transform)\n",
    "test_loader = get_data_loader(test_path, 64, False, test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtQXDY7-tjes"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nwy2SNXJZTw"
   },
   "source": [
    "### Transfer Learning using VGG pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "v9SbLnG0064H"
   },
   "outputs": [],
   "source": [
    "vgg16_weights_path = '/content/drive/MyDrive/Colab Notebooks/pretrained_models/vgg16.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "KAurqNQ9vCWY"
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "vgg16_custom_model = ConvNet('vgg16', vgg16_weights_path, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0SjpbtLhfcN0",
    "outputId": "0c9b4084-f996-4b6b-f143-7959cf1b80e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=200, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): LogSoftmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_custom_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "vIfuJJM8TNHp"
   },
   "outputs": [],
   "source": [
    "fc_layer_idx, conv_layer_idx, _ = get_optimizer_dict(vgg16_custom_model, 0, 0, 0.00003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVMJ77qHXDsV",
    "outputId": "305e1fe7-3635-45cb-da09-cb5d6aa380d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3e-05), (3, 6e-05), (6, 0.00012)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_layer_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEP8K4rAaxwe",
    "outputId": "4016f570-6fed-441c-d61a-7d57425b7d65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3e-05), (3, 9e-05), (6, 0.00027)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEVJpwHEcypO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
