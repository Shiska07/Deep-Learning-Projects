{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10005200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee4cf414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.optim import Adam\n",
    "from collections import OrderedDict\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from IPython.core.display import set_matplotlib_formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33bc7dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Classifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)  # Adjusted input size\n",
    "        self.fc2 = nn.Linear(512, 10)  # 10 classes for CIFAR10\n",
    "        self.out = nn.LogSoftmax(dim=1)\n",
    "        self.loss_fn = nn.NLLLoss()\n",
    "        self.batch_size = 64\n",
    "        self.history = {'train_loss': [], 'train_acc':[], 'val_loss': [], 'val_acc':[]}\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "        \n",
    "        self.classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        y_pred = torch.argmax(torch.exp(logits), 1)\n",
    "        acc = (y_pred == y).sum().item()/self.batch_size\n",
    "        self.training_step_outputs.append((loss.item(), acc))\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        num_items = len(self.training_step_outputs)\n",
    "        cum_loss = 0\n",
    "        cum_acc = 0\n",
    "        for loss, acc in self.training_step_outputs:\n",
    "            cum_loss += loss\n",
    "            cum_acc += acc\n",
    "\n",
    "        self.history['train_loss'].append(cum_loss/num_items)\n",
    "        self.history['train_acc'].append(cum_acc/num_items)\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        y_pred = torch.argmax(torch.exp(logits), 1)\n",
    "        acc = (y_pred == y).sum().item()/self.batch_size\n",
    "        self.validation_step_outputs.append((loss.item(), acc))\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        num_items = len(self.validation_step_outputs)\n",
    "        cum_loss = 0\n",
    "        cum_acc = 0\n",
    "        for loss, acc in self.validation_step_outputs:\n",
    "            cum_loss += loss\n",
    "            cum_acc += acc\n",
    "\n",
    "        self.history['val_loss'].append(cum_loss/num_items)\n",
    "        self.history['val_acc'].append(cum_acc/num_items)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        cifar10_train = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "        return DataLoader(cifar10_train, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        cifar10_val = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "        return DataLoader(cifar10_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        cifar10_test = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "        return DataLoader(cifar10_test, batch_size=self.batch_size)\n",
    "    \n",
    "    def get_history(self):\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a475500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "def plot_history(history):\n",
    "    train_loss = history['train_loss']\n",
    "    val_loss = history['val_loss']\n",
    "    train_acc = history['train_acc']\n",
    "    val_acc = history['val_acc']\n",
    "\n",
    "    # Plot train_loss vs. val_loss\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(train_loss, label='Train Loss', color='blue')\n",
    "    plt.plot(val_loss, label='Validation Loss', color='red')\n",
    "    plt.title('Training Vs Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot train_acc vs. val_acc\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(train_acc, label='Train Accuracy', color='blue')\n",
    "    plt.plot(val_acc, label='Validation Accuracy', color='red')\n",
    "    plt.title('Training Vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "abb7364f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "# initialize trainer\n",
    "trainer = pl.Trainer(max_epochs = 10)\n",
    "\n",
    "model = CIFAR10Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921bc61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | conv1   | Conv2d     | 896   \n",
      "1 | conv2   | Conv2d     | 18.5 K\n",
      "2 | conv3   | Conv2d     | 73.9 K\n",
      "3 | pool    | MaxPool2d  | 0     \n",
      "4 | fc1     | Linear     | 1.0 M \n",
      "5 | fc2     | Linear     | 5.1 K \n",
      "6 | out     | LogSoftmax | 0     \n",
      "7 | loss_fn | NLLLoss    | 0     \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.590     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409f19a8c12e4f4e8134028b8f41dfa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model)\n",
    "history = model.get_history()\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902ce764",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f5540f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b7e49bcc86e7c1f2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b7e49bcc86e7c1f2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b7d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
