{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f07c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6553315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a8060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images should be normalized before being fed to a network for efficient training\n",
    "\n",
    "# these are the mean and std of the data per channel\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd59a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "testset = datasets.CIFAR10(root='~/.pytorch/CIFAR10',download = True, train=False, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ad3c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46503b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "781b84a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 224, 224])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16106d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df9fb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = images[image_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78572008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "052520f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to view image we need the dimensions to be (h, w, channels)\n",
    "np.transpose(img, (1,2,0)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b61c1",
   "metadata": {},
   "source": [
    "### Denormaliztion\n",
    "To denormalize the images for viewing, we need to multiply with the standard deviation and then add the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16ade485",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.ones((5,5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf9633b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0e33dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = np.array([1,2,3], ndmin = 2)\n",
    "mean = np.array([0.25, 0.5, 0.75], ndmin = 2)\n",
    "std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fd89958",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "what would be the result of arr*std+mean?\n",
    "we can see that the shapes of std and mean = (3,)\n",
    "So think about how 'arr' can be even ly divided into 3 parts. \n",
    "As 'arr' has 3 channels in the third dimension, the effect will also be\n",
    "in the third dimension i.e. each element in 'std' amd 'mean' will be applied\n",
    "to each of the channels in the third dimension\n",
    "'''\n",
    "res = arr*std+mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76acb29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.25, 1.25, 1.25, 1.25, 1.25],\n",
       "       [1.25, 1.25, 1.25, 1.25, 1.25],\n",
       "       [1.25, 1.25, 1.25, 1.25, 1.25],\n",
       "       [1.25, 1.25, 1.25, 1.25, 1.25],\n",
       "       [1.25, 1.25, 1.25, 1.25, 1.25]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "435b9c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5, 2.5, 2.5, 2.5, 2.5],\n",
       "       [2.5, 2.5, 2.5, 2.5, 2.5],\n",
       "       [2.5, 2.5, 2.5, 2.5, 2.5],\n",
       "       [2.5, 2.5, 2.5, 2.5, 2.5],\n",
       "       [2.5, 2.5, 2.5, 2.5, 2.5]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2177d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.75, 3.75, 3.75, 3.75, 3.75],\n",
       "       [3.75, 3.75, 3.75, 3.75, 3.75],\n",
       "       [3.75, 3.75, 3.75, 3.75, 3.75],\n",
       "       [3.75, 3.75, 3.75, 3.75, 3.75],\n",
       "       [3.75, 3.75, 3.75, 3.75, 3.75]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5701d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31f03e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.3584211 ,  1.8683473 ,  1.9776908 ],\n",
       "        [ 1.3584211 ,  1.8683473 ,  1.9776908 ],\n",
       "        [ 1.3584211 ,  1.8683473 ,  1.9776908 ],\n",
       "        ...,\n",
       "        [-0.04580877,  0.8004202 ,  0.70535964],\n",
       "        [-0.04580877,  0.8004202 ,  0.70535964],\n",
       "        [-0.04580877,  0.8004202 ,  0.70535964]],\n",
       "\n",
       "       [[ 1.3584211 ,  1.8683473 ,  1.9776908 ],\n",
       "        [ 1.3584211 ,  1.8683473 ,  1.9776908 ],\n",
       "        [ 1.3584211 ,  1.8683473 ,  1.9776908 ],\n",
       "        ...,\n",
       "        [-0.04580877,  0.8004202 ,  0.70535964],\n",
       "        [-0.04580877,  0.8004202 ,  0.70535964],\n",
       "        [-0.04580877,  0.8004202 ,  0.70535964]],\n",
       "\n",
       "       [[ 1.3584211 ,  1.8683473 ,  1.9776908 ],\n",
       "        [ 1.3584211 ,  1.8683473 ,  1.9776908 ],\n",
       "        [ 1.3584211 ,  1.8683473 ,  1.9776908 ],\n",
       "        ...,\n",
       "        [-0.04580877,  0.8004202 ,  0.70535964],\n",
       "        [-0.04580877,  0.8004202 ,  0.70535964],\n",
       "        [-0.04580877,  0.8004202 ,  0.70535964]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.6726604 ,  0.11764706, -0.30553368],\n",
       "        [-1.6726604 ,  0.11764706, -0.30553368],\n",
       "        [-1.6726604 ,  0.11764706, -0.30553368],\n",
       "        ...,\n",
       "        [-2.0836544 , -1.4229691 , -1.3861438 ],\n",
       "        [-2.0836544 , -1.4229691 , -1.3861438 ],\n",
       "        [-2.0836544 , -1.4229691 , -1.3861438 ]],\n",
       "\n",
       "       [[-1.6726604 ,  0.11764706, -0.30553368],\n",
       "        [-1.6726604 ,  0.11764706, -0.30553368],\n",
       "        [-1.6726604 ,  0.11764706, -0.30553368],\n",
       "        ...,\n",
       "        [-2.0836544 , -1.4229691 , -1.3861438 ],\n",
       "        [-2.0836544 , -1.4229691 , -1.3861438 ],\n",
       "        [-2.0836544 , -1.4229691 , -1.3861438 ]],\n",
       "\n",
       "       [[-1.6726604 ,  0.11764706, -0.30553368],\n",
       "        [-1.6726604 ,  0.11764706, -0.30553368],\n",
       "        [-1.6726604 ,  0.11764706, -0.30553368],\n",
       "        ...,\n",
       "        [-2.0836544 , -1.4229691 , -1.3861438 ],\n",
       "        [-2.0836544 , -1.4229691 , -1.3861438 ],\n",
       "        [-2.0836544 , -1.4229691 , -1.3861438 ]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(images[image_id],(1,2,0)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e0532d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = (np.transpose(images[image_id],(1,2,0))).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "127f8fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c33d02a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        ...,\n",
       "        [0.        , 0.8004202 , 0.70535964],\n",
       "        [0.        , 0.8004202 , 0.70535964],\n",
       "        [0.        , 0.8004202 , 0.70535964]],\n",
       "\n",
       "       [[1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        ...,\n",
       "        [0.        , 0.8004202 , 0.70535964],\n",
       "        [0.        , 0.8004202 , 0.70535964],\n",
       "        [0.        , 0.8004202 , 0.70535964]],\n",
       "\n",
       "       [[1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        ...,\n",
       "        [0.        , 0.8004202 , 0.70535964],\n",
       "        [0.        , 0.8004202 , 0.70535964],\n",
       "        [0.        , 0.8004202 , 0.70535964]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.11764706, 0.        ],\n",
       "        [0.        , 0.11764706, 0.        ],\n",
       "        [0.        , 0.11764706, 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.11764706, 0.        ],\n",
       "        [0.        , 0.11764706, 0.        ],\n",
       "        [0.        , 0.11764706, 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.11764706, 0.        ],\n",
       "        [0.        , 0.11764706, 0.        ],\n",
       "        [0.        , 0.11764706, 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.clip(img, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7f7af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the mean and std of the data per channel\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca4e095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor):\n",
    "    tensor = tensor*std + mean\n",
    "    return tensor\n",
    "\n",
    "def show_img(img):\n",
    "    # arrange channels\n",
    "    img = img.numpy().transpose((1,2,0))\n",
    "    \n",
    "    # use mean and std values\n",
    "    img = denormalize(img)\n",
    "    \n",
    "    # clip values and view image\n",
    "    img = np.clip(img,0,1)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edd371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(images[image_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8842cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24526d41ca0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr = np.ones((50, 50))\n",
    "arr[15:35,15:35] = 0\n",
    "plt.imshow(arr, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f4f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
