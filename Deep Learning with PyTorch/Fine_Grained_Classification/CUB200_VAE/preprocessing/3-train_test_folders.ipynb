{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvI97Iy9cRVW",
        "outputId": "82876ddd-c7e6-4ada-9525-f9a95785220a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import multiprocessing\n",
        "from functools import partial\n",
        "from multiprocessing import Pool\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "O1X69pNocWR5"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "1HNalXXDBkOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create df with image names and test info\n",
        "def get_train_test_df(an_file, tr_tst_file):\n",
        "\n",
        "    # read annotations file\n",
        "    df1 = pd.read_csv(an_file, header=None)\n",
        "    df1.columns = ['filename', 'label']\n",
        "\n",
        "    # read .txt file with train info\n",
        "    df2 = pd.read_csv(tr_tst_file, sep=' ', header=None, usecols=[1], names=['train'])\n",
        "\n",
        "    # concat dfs\n",
        "    result_df = pd.concat([df1, df2], axis=1)\n",
        "    return result_df\n",
        "\n",
        "# create annotation file for individual folders\n",
        "def create_annotation_file_for_custom(root_f, ann_path, folder_name, fname):\n",
        "\n",
        "    os.makedirs(ann_path, exist_ok=True)\n",
        "    csv_path = os.path.join(ann_path, fname)\n",
        "    root_folder = os.path.join(root_f, folder_name)\n",
        "\n",
        "    with open(csv_path, 'w', newline='') as csv_file:\n",
        "        fieldnames = ['ImageName', 'Label']\n",
        "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for class_folder in os.listdir(root_folder):\n",
        "            class_path = os.path.join(root_folder, class_folder)\n",
        "\n",
        "            # Process images in the class folder\n",
        "            for file in os.listdir(class_path):\n",
        "\n",
        "                # get label from folder name\n",
        "                label = int(class_folder.split('.')[0])\n",
        "\n",
        "                # Assuming images have common formats like JPG or PNG\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    image_name = os.path.join(class_folder, file)\n",
        "                    writer.writerow({'ImageName': image_name, 'Label': label})\n",
        "\n",
        "        print(f'Successfully {fname} file at {csv_path}.\\n')\n",
        "\n",
        "# create train and test annotations file from df\n",
        "def create_annotations_file(df, ann_dest):\n",
        "\n",
        "    df_train = df[df['train'] == 1][['filename', 'label']]\n",
        "    df_test = df[df['train'] == 0][['filename', 'label']]\n",
        "    df_train.columns =['ImageName', 'Label']\n",
        "    df_test.columns =['ImageName', 'Label']\n",
        "\n",
        "    # for annotations we need\n",
        "    os.makedirs(ann_dest, exist_ok=True)\n",
        "    ann_train = os.path.join(ann_dest, 'annotations_orig_train.csv')\n",
        "    ann_test = os.path.join(ann_dest, 'annotations_orig_test.csv')\n",
        "\n",
        "    df_train.to_csv(ann_train, index=False)\n",
        "    df_test.to_csv(ann_test, index=False)"
      ],
      "metadata": {
        "id": "XsHkSqUMBl4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to pool: for each class folder, copies files to train and test folders\n",
        "def copy_files_custom(class_name, src_path, dst_path, test_size):\n",
        "    class_path = os.path.join(src_path, class_name)\n",
        "    train_folder = os.path.join(dst_path, 'train')\n",
        "    test_folder = os.path.join(dst_path, 'test')\n",
        "\n",
        "    # List all files in the class folder\n",
        "    files = os.listdir(class_path)\n",
        "\n",
        "    # Split the files into train and test sets\n",
        "    train_files, test_files = train_test_split(files, test_size=test_size, random_state=42)\n",
        "\n",
        "    # Create subdirectories for this class in the train and test folders\n",
        "    train_class_folder = os.path.join(train_folder, class_name)\n",
        "    test_class_folder = os.path.join(test_folder, class_name)\n",
        "    os.makedirs(train_class_folder, exist_ok=True)\n",
        "    os.makedirs(test_class_folder, exist_ok=True)\n",
        "\n",
        "    # Move the train files to the train class folder\n",
        "    for file in train_files:\n",
        "        src = os.path.join(class_path, file)\n",
        "        dst = os.path.join(train_class_folder, file)\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "    # Move the test files to the test class folder\n",
        "    for file in test_files:\n",
        "        src = os.path.join(class_path, file)\n",
        "        dst = os.path.join(test_class_folder, file)\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "# creates custom train test split\n",
        "def create_train_test_split_folders_custom(src_path, dst_path, test_size = 0.3):\n",
        "\n",
        "    classes = os.listdir(src_path)\n",
        "\n",
        "    # if destination folder does not exist, create folder\n",
        "    if not os.path.exists(dst_path):\n",
        "        os.makedirs(dst_path)\n",
        "\n",
        "    # Create train and test folders if they don't exist\n",
        "    train_folder = os.path.join(dst_path, 'train')\n",
        "    test_folder = os.path.join(dst_path, 'test')\n",
        "    os.makedirs(train_folder, exist_ok=True)\n",
        "    os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "    pool = multiprocessing.Pool(processes=4)\n",
        "\n",
        "    copy_files_custom_x=partial(copy_files_custom, src_path=src_path, dst_path=dst_path, test_size=test_size)\n",
        "    pool.map(copy_files_custom_x, classes)\n",
        "\n",
        "    print(f'Finished creating custom train/test split folders.')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# function to pool: for each class folder, copies files to train and test folders\n",
        "def copy_files_original(class_name, src_path, dst_path, train_test_df):\n",
        "    train_folder = os.path.join(dst_path, 'train')\n",
        "    test_folder = os.path.join(dst_path, 'test')\n",
        "    class_path_src = os.path.join(src_path, class_name)\n",
        "\n",
        "    # List all files in the class folder\n",
        "    files = os.listdir(class_path_src)\n",
        "\n",
        "    # for each file in the class\n",
        "    for file in files:\n",
        "\n",
        "        # src file path\n",
        "        file_path_src = os.path.join(class_path_src, file)\n",
        "\n",
        "        # check if file is train or test\n",
        "        file_key = os.path.join(class_name, file)\n",
        "        train_val = train_test_df[train_test_df['filename'] == file_key]['train']).iloc[0]\n",
        "\n",
        "        if train_val == int(1):\n",
        "            class_path_dst = os.path.join(train_folder, class_name)\n",
        "            file_path_dst = os.path.join(train_folder, class_name, file)\n",
        "        elif train_val == int(0):\n",
        "            class_path_dst = os.path.join(test_folder, class_name)\n",
        "            file_path_dst = os.path.join(test_folder, class_name, file)\n",
        "\n",
        "        # copy file\n",
        "        os.makedirs(class_path_dst, exist_ok=True)\n",
        "        shutil.copy(file_path_src, file_path_dst)\n",
        "\n",
        "# creates train/test split based on the original file\n",
        "def create_train_test_split_folders_original(src_path, dst_path, train_test_df):\n",
        "\n",
        "    # list of class names\n",
        "    classes = os.listdir(src_path)\n",
        "\n",
        "    # if destination folder does not exist, create folder\n",
        "    if not os.path.exists(dst_path):\n",
        "        os.makedirs(dst_path)\n",
        "\n",
        "    # Create train and test folders if they don't exist\n",
        "    train_folder = os.path.join(dst_path, 'train')\n",
        "    test_folder = os.path.join(dst_path, 'test')\n",
        "    os.makedirs(train_folder, exist_ok=True)\n",
        "    os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "    pool = multiprocessing.Pool(processes=4)\n",
        "\n",
        "    copy_files_original_x=partial(copy_files_original, src_path=src_path, dst_path=dst_path, train_test_df=train_test_df)\n",
        "    pool.map(copy_files_original_x, classes)\n",
        "    print(f'Finished creating original train/test split folders.')\n"
      ],
      "metadata": {
        "id": "v9UGyxf9xfqy"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    images_dir_path = '/content/drive/MyDrive/Colab Notebooks/Data/CUB_200_2011/images_cropped'\n",
        "    train_test_dest1 = '/content/drive/MyDrive/Colab Notebooks/Data/CUB_200_2011/train_test_original_cropped'\n",
        "    train_test_dest2 = '/content/drive/MyDrive/Colab Notebooks/Data/CUB_200_2011/train_test_custom_cropped'\n",
        "    annotations_file = '/content/drive/MyDrive/Colab Notebooks/Data/CUB_200_2011/image_labels.csv'\n",
        "    ann_dest1 = '/content/drive/MyDrive/Colab Notebooks/Data/CUB_200_2011/train_test_original_cropped/annotations'\n",
        "    ann_dest2 = '/content/drive/MyDrive/Colab Notebooks/Data/CUB_200_2011/train_test_custom_cropped/annotations'\n",
        "    train_test_file = '/content/drive/MyDrive/Colab Notebooks/Data/CUB_200_2011/train_test_split.txt'\n",
        "\n",
        "    # create concatenated df with filenames and train info\n",
        "    df = get_train_test_df(annotations_file, train_test_file)\n",
        "    return df\n",
        "    # create train/test folders\n",
        "    # create_train_test_split_folders_custom(images_dir_path, train_test_dest2)\n",
        "    create_train_test_split_folders_original(images_dir_path, train_test_dest1, df)\n",
        "\n",
        "    # create annotation files\n",
        "    # create_annotations_file(df, ann_dest1)\n"
      ],
      "metadata": {
        "id": "v7xpSw3iV-vt"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = main()"
      ],
      "metadata": {
        "id": "zGcXgepNWwO2"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oca8Te2cPf7k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}