{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16310,
     "status": "ok",
     "timestamp": 1696729564587,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "G9nO9rY_PFiR",
    "outputId": "ffe812b0-4ccb-45db-eac5-d7ef75656c85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1696729565021,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "j4sBZ6MrPOI5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16460,
     "status": "ok",
     "timestamp": 1696729581477,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "a_iWKkpCPeah",
    "outputId": "34e72682-89ae-46a2-ba66-2c64f6e0a932"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightning\n",
      "  Downloading lightning-2.0.9.post0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Jinja2<5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (3.1.2)\n",
      "Requirement already satisfied: PyYAML<8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.1)\n",
      "Collecting arrow<3.0,>=1.2.0 (from lightning)\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting backoff<4.0,>=2.2.1 (from lightning)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.11.2)\n",
      "Requirement already satisfied: click<10.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (8.1.7)\n",
      "Collecting croniter<1.5.0,>=1.3.0 (from lightning)\n",
      "  Downloading croniter-1.4.1-py2.py3-none-any.whl (19 kB)\n",
      "Collecting dateutils<2.0 (from lightning)\n",
      "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
      "Collecting deepdiff<8.0,>=5.7.0 (from lightning)\n",
      "  Downloading deepdiff-6.6.0-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.0/73.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastapi<2.0,>=0.92.0 (from lightning)\n",
      "  Downloading fastapi-0.103.2-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec<2025.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2023.6.0)\n",
      "Collecting inquirer<5.0,>=2.10.0 (from lightning)\n",
      "  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\n",
      "Collecting lightning-cloud>=0.5.38 (from lightning)\n",
      "  Downloading lightning_cloud-0.5.39-py3-none-any.whl (693 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.9/693.9 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lightning-utilities<2.0,>=0.7.0 (from lightning)\n",
      "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.23.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lightning) (23.2)\n",
      "Requirement already satisfied: psutil<7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (5.9.5)\n",
      "Requirement already satisfied: pydantic<2.2.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.10.13)\n",
      "Collecting python-multipart<2.0,>=0.0.5 (from lightning)\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.31.0)\n",
      "Requirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (13.6.0)\n",
      "Collecting starlette (from lightning)\n",
      "  Downloading starlette-0.31.1-py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting starsessions<2.0,>=1.2.1 (from lightning)\n",
      "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: torch<4.0,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.0.1+cu118)\n",
      "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
      "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.1)\n",
      "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (5.7.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.5.0)\n",
      "Requirement already satisfied: urllib3<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.0.6)\n",
      "Collecting uvicorn<2.0 (from lightning)\n",
      "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: websocket-client<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.6.3)\n",
      "Collecting websockets<13.0 (from lightning)\n",
      "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-lightning (from lightning)\n",
      "  Downloading pytorch_lightning-2.0.9.post0-py3-none-any.whl (727 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.7/727.7 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow<3.0,>=1.2.0->lightning)\n",
      "  Downloading types_python_dateutil-2.8.19.14-py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.5)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateutils<2.0->lightning) (2023.3.post1)\n",
      "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff<8.0,>=5.7.0->lightning)\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi<2.0,>=0.92.0->lightning) (3.7.1)\n",
      "Collecting starlette (from lightning)\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec<2025.0,>=2022.5.0->lightning) (3.8.5)\n",
      "Collecting blessed>=1.19.0 (from inquirer<5.0,>=2.10.0->lightning)\n",
      "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-editor>=1.0.4 (from inquirer<5.0,>=2.10.0->lightning)\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting readchar>=3.0.6 (from inquirer<5.0,>=2.10.0->lightning)\n",
      "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<5.0->lightning) (2.1.3)\n",
      "Requirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from lightning-cloud>=0.5.38->lightning) (2.3.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.38->lightning) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning) (2.16.1)\n",
      "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (3.12.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (3.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<4.0,>=1.11.0->lightning) (3.27.6)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<4.0,>=1.11.0->lightning) (17.0.2)\n",
      "Collecting h11>=0.8 (from uvicorn<2.0->lightning)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi<2.0,>=0.92.0->lightning) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi<2.0,>=0.92.0->lightning) (1.1.3)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.8)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<15.0,>=12.3.0->lightning) (0.1.2)\n",
      "Requirement already satisfied: setuptools>=41.0 in /usr/local/lib/python3.10/dist-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning) (67.7.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.11.0->lightning) (1.3.0)\n",
      "Installing collected packages: types-python-dateutil, python-editor, websockets, readchar, python-multipart, ordered-set, lightning-utilities, h11, blessed, backoff, uvicorn, starlette, inquirer, deepdiff, dateutils, croniter, arrow, starsessions, fastapi, lightning-cloud, torchmetrics, pytorch-lightning, lightning\n",
      "Successfully installed arrow-1.3.0 backoff-2.2.1 blessed-1.20.0 croniter-1.4.1 dateutils-0.6.12 deepdiff-6.6.0 fastapi-0.103.2 h11-0.14.0 inquirer-3.1.3 lightning-2.0.9.post0 lightning-cloud-0.5.39 lightning-utilities-0.9.0 ordered-set-4.1.0 python-editor-1.0.4 python-multipart-0.0.6 pytorch-lightning-2.0.9.post0 readchar-4.0.5 starlette-0.27.0 starsessions-1.3.0 torchmetrics-1.2.0 types-python-dateutil-2.8.19.14 uvicorn-0.23.2 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 14768,
     "status": "ok",
     "timestamp": 1696729596241,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "QIfGih6LPWQt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.optim import Adam\n",
    "from collections import OrderedDict\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1696729596242,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "AQQOjGhYUDH_"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjIh6F1qRO_C"
   },
   "source": [
    "### Define Custom Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1696729849921,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "jNsx8CpvRId9"
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import set_matplotlib_formats\n",
    "class ConvNet(pl.LightningModule):\n",
    "    def __init__(self, pretrained_model_name, pretrained_model_path, num_classes, resizing_factor, base_lr, batch_size, train_path, test_path):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.pretrained_model_name = pretrained_model_name\n",
    "        self.pretrained_model_path = pretrained_model_path\n",
    "        self.num_classes = num_classes\n",
    "        self.resizing_factor = resizing_factor\n",
    "        self.lr = base_lr\n",
    "        self.batch_size = batch_size\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.in_feat = None\n",
    "        self.model = None\n",
    "\n",
    "        # dict to store training progress per epoch\n",
    "        self.history = {'train_loss': [],\n",
    "               'val_loss': [],\n",
    "               'train_acc':[],\n",
    "               'val_acc':[]\n",
    "               }\n",
    "\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "\n",
    "        # transfer learning parameters\n",
    "        self.classifiers_n = -1\n",
    "        self.features_n = -1\n",
    "\n",
    "        # check for GPU availability\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "\n",
    "        # load model architectures without weight\n",
    "        if use_gpu:\n",
    "            self.model = getattr(models, self.pretrained_model_name)().cuda()\n",
    "        else:\n",
    "            self.model = getattr(models, self.pretrained_model_name)()\n",
    "\n",
    "        # load pre-trained weights\n",
    "        if use_gpu:\n",
    "            self.model.load_state_dict(torch.load(self.pretrained_model_path))\n",
    "        else:\n",
    "            self.model.load_state_dict(torch.load(self.pretrained_model_path, map_location=torch.device('cpu')))\n",
    "\n",
    "        # get input dimension of the fc layer to be replaced and index of the last fc layer\n",
    "        self.in_feat = self.model.classifier[-1].in_features\n",
    "        fc_idx = len(self.model.classifier) - 1\n",
    "\n",
    "        custom_fc = nn.Sequential(nn.Linear(self.in_feat, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(512, self.num_classes),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.LogSoftmax(dim=1))\n",
    "\n",
    "        # add custom fc layers to model\n",
    "        self.model.classifier[fc_idx] = custom_fc\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    # freezes all layers in the model\n",
    "    def freeze_all_layers(self):\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # unfreeze last 'n' fully connected layers\n",
    "    def unfreeze_last_n_fc_layers(self, n):\n",
    "\n",
    "        # if n == -1 don't unfreeze any layers\n",
    "        if n == -1:\n",
    "            return 0\n",
    "\n",
    "        n = n*2 # since weights and bias are included as separate\n",
    "        total_layers = len(list(self.model.classifier.parameters()))\n",
    "\n",
    "        # invalid n\n",
    "        if n > total_layers:\n",
    "            print(f\"Warning: There are only {total_layers} layers in the model. Cannot unfreeze {n} layers.\")\n",
    "\n",
    "        # if n == 0 unfreeze all layers\n",
    "        elif n == 0:\n",
    "            for param in self.model.classifier.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            for i, param in enumerate(self.model.classifier.parameters()):\n",
    "                if i >= (total_layers - n):\n",
    "                    param.requires_grad = True\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "\n",
    "\n",
    "    # unfreeze last 'n' fully connected layers\n",
    "    def unfreeze_last_n_conv_layers(self, n):\n",
    "\n",
    "        # if n == -1 don't unfreeze any layers\n",
    "        if n == -1:\n",
    "            return 0\n",
    "\n",
    "        n = n*2 # since weights and bias are included as separate\n",
    "        total_layers = len(list(self.model.features.parameters()))\n",
    "\n",
    "        # invalid n\n",
    "        if n > total_layers:\n",
    "            print(f\"Warning: There are only {total_layers} layers in the model. Cannot unfreeze {n} layers.\")\n",
    "        # if n == 0 unfreeze all layers\n",
    "        elif n == 0:\n",
    "            for param in self.model.features.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            for i, param in enumerate(self.model.features.parameters()):\n",
    "                if i >= total_layers - n:\n",
    "                    param.requires_grad = True\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "    # set parameters for transfer learning\n",
    "    def set_transfer_learning_params(self, unfreeze_n_fc, unfreeze_n_conv):\n",
    "        self.classifier_n = unfreeze_n_fc\n",
    "        self.features_n = unfreeze_n_conv\n",
    "        self.freeze_all_layers()\n",
    "        self.unfreeze_last_n_fc_layers(unfreeze_n_fc)\n",
    "        self.unfreeze_last_n_conv_layers(unfreeze_n_conv)\n",
    "\n",
    "    def get_optimizer_params_list(self):\n",
    "        # list of dictionaries to store parameter values\n",
    "        params_list = []\n",
    "\n",
    "        # multiplying factor\n",
    "        f_fc = 10\n",
    "        f_conv = 2\n",
    "\n",
    "        if self.classifier_n != -1:\n",
    "            if self.classifier_n == 0:\n",
    "                named_params = list(name for name, _ in self.model.classifier.named_parameters())\n",
    "                layer_indices = list(OrderedDict.fromkeys([int(name.split('.')[0]) for name in named_params]))\n",
    "            else:\n",
    "                # get indices of the last 'n' layers in the model\n",
    "                named_params = list(name for name, _ in self.model.classifier.named_parameters())\n",
    "                layer_indices = list(OrderedDict.fromkeys([int(name.split('.')[0]) for name in named_params[-self.classifier_n*2:]]))\n",
    "            for i, index_val in enumerate(layer_indices):\n",
    "                #params_list.append({'params':self.model.classifier[index_val].parameters(), 'lr': self.lr*f_fc})\n",
    "                params_list.append({'params':self.model.classifier[index_val].parameters(), 'lr': 0.001})\n",
    "\n",
    "        if self.features_n != -1:\n",
    "            if self.features_n == 0:\n",
    "                named_params = list(name for name, _ in self.model.features.named_parameters())\n",
    "                layer_indices = list(OrderedDict.fromkeys([int(name.split('.')[0]) for name in named_params]))\n",
    "            else:\n",
    "                # get indices of the last 'n' layers in the model\n",
    "                named_params = list(name for name, _ in self.model.features.named_parameters())\n",
    "                layer_indices = list(OrderedDict.fromkeys([int(name.split('.')[0]) for name in named_params[-self.features_n*2:]]))\n",
    "            for i, index_val in enumerate(layer_indices):\n",
    "                # params_list.append({'params':self.model.features[index_val].parameters(), 'lr': self.lr*(f_conv*(i+1))})\n",
    "                params_list.append({'params':self.model.features[index_val].parameters(), 'lr': 0.001})\n",
    "\n",
    "        if self.classifier_n == self.features_n == -1:\n",
    "            return self.model.parameters()\n",
    "\n",
    "        return params_list\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        params_list = self.get_optimizer_params_list()\n",
    "        optimizer = Adam(params_list, lr = self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logps = self(x)\n",
    "        loss = F.nll_loss(logps, y)\n",
    "        y_pred = torch.argmax(torch.exp(logps), 1)\n",
    "        acc = (y_pred == y).sum().item()/len(y)\n",
    "        self.log('train_loss', loss.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.training_step_outputs.append((loss.item(), acc))\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        num_items = len(self.training_step_outputs)\n",
    "        cum_loss = 0\n",
    "        cum_acc = 0\n",
    "        for loss, acc in self.training_step_outputs:\n",
    "            cum_loss += loss\n",
    "            cum_acc += acc\n",
    "\n",
    "        self.history['train_loss'].append(cum_loss/num_items)\n",
    "        self.history['train_acc'].append(cum_acc/num_items)\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logps = self(x)\n",
    "        loss = F.nll_loss(logps, y)\n",
    "        y_pred = torch.argmax(torch.exp(logps), 1)\n",
    "        acc = (y_pred == y).sum().item()/len(y)\n",
    "        self.log('val_loss', loss.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.validation_step_outputs.append((loss.item(), acc))\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        num_items = len(self.validation_step_outputs)\n",
    "        cum_loss = 0\n",
    "        cum_acc = 0\n",
    "        for loss, acc in self.validation_step_outputs:\n",
    "            cum_loss += loss\n",
    "            cum_acc += acc\n",
    "\n",
    "        self.history['val_loss'].append(cum_loss/num_items)\n",
    "        self.history['val_acc'].append(cum_acc/num_items)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logps = self(x)\n",
    "        loss = F.nll_loss(logps, y)\n",
    "        y_pred = torch.argmax(torch.exp(logps), 1)\n",
    "        acc = (y_pred == y).sum().item()/len(y)\n",
    "        self.log('test_loss', loss.item(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('test_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.test_step_outputs.append((loss.item(), acc))\n",
    "        return loss\n",
    "\n",
    "    # create dataset objects\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "\n",
    "        # define transformers\n",
    "        train_transform = transforms.Compose([\n",
    "                transforms.Resize(self.resizing_factor),\n",
    "                transforms.RandomHorizontalFlip(0.5),\n",
    "                transforms.RandomRotation(15),\n",
    "                transforms.RandomAffine(degrees = 10,\n",
    "                                        translate = (0.2, 0.2), shear = 10),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)])\n",
    "\n",
    "        test_transform = transforms.Compose([transforms.Resize(self.resizing_factor),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize(mean, std)])\n",
    "\n",
    "        # create datasets\n",
    "        train = torchvision.datasets.ImageFolder(self.train_path, transform=train_transform)\n",
    "        total_items = len(train)\n",
    "        val_size = int(total_items*0.2)\n",
    "        train_size = total_items - val_size\n",
    "        self.train_dataset, self.val_dataset = random_split(train, [train_size, val_size])\n",
    "        self.test_dataset = torchvision.datasets.ImageFolder(self.test_path, transform=test_transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, self.batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, self.batch_size, shuffle=False)\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdZ2NAQlWYy9"
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1696729853629,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "tDIIeCQbWa7I"
   },
   "outputs": [],
   "source": [
    "# plot history\n",
    "def plot_history(history):\n",
    "    train_loss = history['train_loss']\n",
    "    val_loss = history['val_loss']\n",
    "    train_acc = history['train_acc']\n",
    "    val_acc = history['val_acc']\n",
    "\n",
    "    # Plot train_loss vs. val_loss\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(train_loss, label='Train Loss', color='blue')\n",
    "    plt.plot(val_loss, label='Validation Loss', color='red')\n",
    "    plt.title('Training Vs Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot train_acc vs. val_acc\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(train_acc, label='Train Accuracy', color='blue')\n",
    "    plt.plot(val_acc, label='Validation Accuracy', color='red')\n",
    "    plt.title('Training Vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfQ5spVwc6G_"
   },
   "source": [
    "### Transfer Learning Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1696729856905,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "iaIdjJh4c9V7"
   },
   "outputs": [],
   "source": [
    "def train_custom_fc_layers(trainer, model):\n",
    "    # freeze all layers except the last two fc layers\n",
    "    unfreeze_n_fc = 2\n",
    "    unfreeze_n_conv = -1\n",
    "    model.set_transfer_learning_params(unfreeze_n_fc, unfreeze_n_conv)\n",
    "\n",
    "    # train model\n",
    "    trainer.fit(model)\n",
    "\n",
    "    # get training history\n",
    "    history = model.get_history()\n",
    "\n",
    "    # plot history\n",
    "    plot_history(history)\n",
    "\n",
    "    return history\n",
    "\n",
    "def train_entire_fc_block(trainer, model):\n",
    "    # freeze all layers except the fc block\n",
    "    unfreeze_n_fc = 0\n",
    "    unfreeze_n_conv = -1\n",
    "    model.set_transfer_learning_params(unfreeze_n_fc, unfreeze_n_conv)\n",
    "\n",
    "    # train model\n",
    "    trainer.fit(model)\n",
    "\n",
    "    # get training history\n",
    "    history = model.get_history()\n",
    "\n",
    "    # plot history\n",
    "    plot_history(history)\n",
    "\n",
    "    return history\n",
    "\n",
    "def train_conv_layers(trainer, model):\n",
    "    # freeze all layers except the last two conv layers\n",
    "    unfreeze_n_fc = -1\n",
    "    unfreeze_n_conv = 2\n",
    "    model.set_transfer_learning_params(unfreeze_n_fc, unfreeze_n_conv)\n",
    "\n",
    "    # train model\n",
    "    trainer.fit(model)\n",
    "\n",
    "    # get training history\n",
    "    history = model.get_history()\n",
    "\n",
    "    # plot history\n",
    "    plot_history(history)\n",
    "\n",
    "    return history\n",
    "\n",
    "def fine_tune_model(trainer, model):\n",
    "    # freeze all layers except the last two conv layers and the fc block\n",
    "    unfreeze_n_fc = 0\n",
    "    unfreeze_n_conv = 2\n",
    "    model.set_transfer_learning_params(unfreeze_n_fc, unfreeze_n_conv)\n",
    "\n",
    "    # train model\n",
    "    trainer.fit(model)\n",
    "\n",
    "    # get training history\n",
    "    history = model.get_history()\n",
    "\n",
    "    # plot history\n",
    "    plot_history(history)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1696729859271,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "1JNyxybWSuQi"
   },
   "outputs": [],
   "source": [
    "# define variables\n",
    "pretrained_model_name = 'vgg16'\n",
    "pretrained_model_path = '/content/drive/MyDrive/Colab Notebooks/pretrained_models/vgg16.pth'\n",
    "num_classes = 10\n",
    "resizing_factor = (224, 224)\n",
    "base_lr = 0.001\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "train_path = '/content/drive/MyDrive/Colab Notebooks/Data/CUB_200_2011/train_test_cropped/train'\n",
    "test_path = '/content/drive/MyDrive/Colab Notebooks/Data/CUB_200_2011/train_test_cropped/test'\n",
    "log_dir = '/content/drive/MyDrive/Colab Notebooks/logs/lightning_logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8732,
     "status": "ok",
     "timestamp": 1696729868975,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "npD8DWWhRe_6",
    "outputId": "c2997b47-9196-4d62-b096-3bd6a4b487bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# logger\n",
    "logger = TensorBoardLogger(log_dir)\n",
    "\n",
    "# load trainer\n",
    "trainer = pl.Trainer(limit_train_batches=20, limit_test_batches=10, limit_val_batches=10,\n",
    "                         max_epochs = epochs, logger = logger)\n",
    "# create model\n",
    "model = ConvNet(pretrained_model_name, pretrained_model_path, num_classes, resizing_factor,\n",
    "                base_lr, batch_size, train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3de9857782444ceba08925b5ec193c14",
      "8d8a02ed7d2743099bf88efda906f23a",
      "e6671542e26045fcab6741b89f576747",
      "13dae15d30444f528ba7c536c85ed6ec",
      "92db49d7020a4ac5b57e8855a644116f",
      "c0045fe6684a4380a908ba797d025495",
      "f1c1e6b830954ffd959b414b94d7c22e",
      "1d8599c912b74badb1d2f7e89e783ff9",
      "18a05528f45a49b4ba0ae6ee91efdf71",
      "b2adebaed4404b8ca67a27b60e188af4",
      "bbe1a6606fc94ea59aadc1c4ad5a13c7"
     ]
    },
    "executionInfo": {
     "elapsed": 89622,
     "status": "error",
     "timestamp": 1696729962024,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "N7K5ScACUt_U",
    "outputId": "3ea94da2-0724-4faf-c94f-13542e7c86d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | VGG  | 136 M \n",
      "-------------------------------\n",
      "2.1 M     Trainable params\n",
      "134 M     Non-trainable params\n",
      "136 M     Total params\n",
      "545.453   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de9857782444ceba08925b5ec193c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-74bb8b97a1f6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_custom_fc_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-b7c4edaa599e>\u001b[0m in \u001b[0;36mtrain_custom_fc_layers\u001b[0;34m(trainer, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# get training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0m_verify_strategy_supports_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         )\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m             \u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_sanity_check_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mprevious_dataloader_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;31m# run step hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;31m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36m_evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mhook_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test_step\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_processed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValidationStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-c89524dddf41>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mlogps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2702\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2704\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 27 is out of bounds."
     ]
    }
   ],
   "source": [
    "history = train_custom_fc_layers(trainer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1696729606247,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "A-DAY7z5Zoa9"
   },
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "aborted",
     "timestamp": 1696729606247,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "qSaV9s4OpepW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 58078,
     "status": "aborted",
     "timestamp": 1696729606247,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "XTpDTdBWpySU"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 58076,
     "status": "aborted",
     "timestamp": 1696729606248,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "X30zKAF6vbgG"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 58074,
     "status": "aborted",
     "timestamp": 1696729606248,
     "user": {
      "displayName": "Shiska Raut",
      "userId": "09726644257059784788"
     },
     "user_tz": 300
    },
    "id": "SAHsboqUviCG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6PLWFK7uG0Uq16spDKLdw",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13dae15d30444f528ba7c536c85ed6ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2adebaed4404b8ca67a27b60e188af4",
      "placeholder": "​",
      "style": "IPY_MODEL_bbe1a6606fc94ea59aadc1c4ad5a13c7",
      "value": " 0/2 [00:00&lt;?, ?it/s]"
     }
    },
    "18a05528f45a49b4ba0ae6ee91efdf71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1d8599c912b74badb1d2f7e89e783ff9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3de9857782444ceba08925b5ec193c14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d8a02ed7d2743099bf88efda906f23a",
       "IPY_MODEL_e6671542e26045fcab6741b89f576747",
       "IPY_MODEL_13dae15d30444f528ba7c536c85ed6ec"
      ],
      "layout": "IPY_MODEL_92db49d7020a4ac5b57e8855a644116f"
     }
    },
    "8d8a02ed7d2743099bf88efda906f23a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0045fe6684a4380a908ba797d025495",
      "placeholder": "​",
      "style": "IPY_MODEL_f1c1e6b830954ffd959b414b94d7c22e",
      "value": "Sanity Checking DataLoader 0:   0%"
     }
    },
    "92db49d7020a4ac5b57e8855a644116f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "b2adebaed4404b8ca67a27b60e188af4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbe1a6606fc94ea59aadc1c4ad5a13c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c0045fe6684a4380a908ba797d025495": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6671542e26045fcab6741b89f576747": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d8599c912b74badb1d2f7e89e783ff9",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_18a05528f45a49b4ba0ae6ee91efdf71",
      "value": 0
     }
    },
    "f1c1e6b830954ffd959b414b94d7c22e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
