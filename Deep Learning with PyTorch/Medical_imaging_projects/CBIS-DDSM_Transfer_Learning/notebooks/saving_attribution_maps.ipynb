{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qe2L7784Gphl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlLjKxzO9Nk5",
        "outputId": "6fbcc9e8-b891-478c-9962-fe0902739e91"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchsummary\n",
        "from torch.optim import Adam\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "Nip7Ph1RHepR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install captum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQB9hGwISJT7",
        "outputId": "56cb4079-b415-49fa-830d-829b8aef5398"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting captum\n",
            "  Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import captum\n",
        "from captum.attr import LayerGradCam, LayerAttribution\n",
        "from captum.attr import visualization as viz\n",
        "from matplotlib.colors import LinearSegmentedColormap"
      ],
      "metadata": {
        "id": "TA1azldFHlxV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0nvU5JLHoKe",
        "outputId": "11fdcb4b-8e7a-4296-f05e-b95b82dfb124"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "gduQG_XYHW2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# these are the mean and std of the data per channel\n",
        "mean = [0.44749328, 0.44749328, 0.44749328]\n",
        "std = [0.09886961, 0.09886961, 0.09886961]\n",
        "\n",
        "class_dict = { 0:'BACKGROUND', 1:'BENIGN_Calc', 2:'BENIGN_Mass', 3:'MALIGNANT_Calc', 4:'MALIGNANT_Mass'}\n",
        "\n",
        "def denormalize(tensor):\n",
        "    tensor = tensor*std + mean\n",
        "    return tensor\n",
        "\n",
        "# function for viewling image\n",
        "def view_normalized_image(img):\n",
        "    # arrange channels\n",
        "    img = img.numpy().transpose((1,2,0))\n",
        "\n",
        "    # use mean and std values\n",
        "    img = denormalize(img)\n",
        "\n",
        "    min_val = np.min(img)\n",
        "    max_val = np.max(img)\n",
        "\n",
        "    # Normalize the data to the range [0, 1]\n",
        "    normalized_img = (img - min_val) / (max_val - min_val)\n",
        "\n",
        "    return np.float32(normalized_img)\n",
        "\n",
        "def normalize_image(img):\n",
        "    min_val = np.min(img)\n",
        "    max_val = np.max(img)\n",
        "\n",
        "    normalized_img = (img - min_val) / (max_val - min_val)\n",
        "    normalized_img *= 255\n",
        "    return normalized_img.astype(int)\n",
        "\n",
        "def load_parameters(json_file):\n",
        "    try:\n",
        "        with open(json_file, 'r') as file:\n",
        "            parameters = json.load(file)\n",
        "        return parameters\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: JSON file '{json_file}' not found.\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: JSON file '{json_file}' is not a valid JSON file.\")\n",
        "        return None\n",
        "\n",
        "class TrainedModel(nn.Module):\n",
        "    def __init__(self, model_arc_path, model_weights_path, name):\n",
        "        super(TrainedModel, self).__init__()\n",
        "        self.model = torch.load(model_arc_path)\n",
        "        self.model.load_state_dict(torch.load(model_weights_path))\n",
        "        self.name = name\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# custom dataset which also returns name of the image\n",
        "class CustomTestDataset(Dataset):\n",
        "    def __init__(self, img_dir, annotations_file, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.img_labels.iloc[idx, 0]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path)\n",
        "        rgb_image = image.convert(\"RGB\")\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            rgb_image = self.transform(rgb_image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return rgb_image, int(label), img_name\n",
        "\n",
        "def get_test_dataloader(image_folder_path, annotations_file_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)\n",
        "        ])\n",
        "\n",
        "    # create two datsets, one with original size and one resized\n",
        "    ddsm_test = CustomTestDataset(image_folder_path, annotations_file_path,\n",
        "                                          transform=transform)\n",
        "\n",
        "    dataloader_test = DataLoader(ddsm_test, batch_size=1, num_workers=2)\n",
        "    return dataloader_test\n",
        "\n",
        "def find_corresponding_mask(directory, image_name):\n",
        "    # Construct the full path to the image\n",
        "    image_path = os.path.join(directory, image_name)\n",
        "\n",
        "    # Check if the image file exists\n",
        "    if os.path.exists(image_path):\n",
        "        # Read the image using cv2\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Check if the image was successfully read\n",
        "        if image is not None:\n",
        "            return image\n",
        "        else:\n",
        "            print(f\"Error: Unable to read image '{image_name}'.\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"Error: Image '{image_name}' not found in the specified directory.\")\n",
        "        return None\n",
        "\n",
        "def find_corresponding_image(directory, image_name):\n",
        "    # Construct the full path to the image\n",
        "    image_path = os.path.join(directory, image_name)\n",
        "\n",
        "    # Check if the image file exists\n",
        "    if os.path.exists(image_path):\n",
        "        # Read the image using cv2\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Check if the image was successfully read\n",
        "        if image is not None:\n",
        "            return image\n",
        "        else:\n",
        "            print(f\"Error: Unable to read image '{image_name}'.\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"Error: Image '{image_name}' not found in the specified directory.\")\n",
        "        return None\n",
        "\n",
        "def save_1_3_plot(original_img, heatmap, binary_mask, name, dst_folder):\n",
        "    # resize mask if necessary\n",
        "    if original_img.shape[:2] != binary_mask.shape[:2]:\n",
        "        binary_mask = cv2.resize(np.uint8(binary_mask), (original_img.shape[:2][1],original_img.shape[:2][0]),\n",
        "                                  interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    images = [original_img, heatmap, binary_mask]\n",
        "    titles = [\"Original Image\", \"Heatmap\", \"Ground Truth\"]\n",
        "\n",
        "    for ax, image, title in zip(axes, images, titles):\n",
        "        if title == \"Ground Truth\":\n",
        "            ax.imshow(image, cmap = 'gray')\n",
        "        else:\n",
        "            ax.imshow(image)\n",
        "        ax.set_title(title)\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    img_path = os.path.join(dst_folder, name)\n",
        "    plt.savefig(img_path)\n"
      ],
      "metadata": {
        "id": "Uvl7wcb8HNe7"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attribution map functions"
      ],
      "metadata": {
        "id": "nxMn06T3H3Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# returns heatmap overlayed on the original image\n",
        "def get_attention_map(model_name, custom_model, x, x_fullsize, layer, alpha):\n",
        "\n",
        "    custom_model.to(device)\n",
        "    x = x.to(device)\n",
        "    custom_model.eval()\n",
        "\n",
        "    # convert data to tensor dimension\n",
        "    input_img = x.unsqueeze(0)\n",
        "    output = F.softmax(custom_model(input_img), dim = 1)\n",
        "\n",
        "    prediction_score, pred_label_idx = torch.topk(output, 1)\n",
        "    pred_label_idx.squeeze_()\n",
        "\n",
        "    # get grad cam results\n",
        "    if 'vgg' in model_name:\n",
        "        layer_of_interest = custom_model.model.features[34]\n",
        "    elif 'resnet' in model_name:\n",
        "        layer_of_interest = custom_model.model.layer4[2].conv3\n",
        "\n",
        "    layer_gradcam = LayerGradCam(custom_model, layer_of_interest)\n",
        "\n",
        "    # this is the heatmap for the original feature map\n",
        "    attributions_lgc = layer_gradcam.attribute(input_img, target=pred_label_idx)\n",
        "    attributions_lgc = attributions_lgc.squeeze(1).cpu().permute(1,2,0).detach().numpy()\n",
        "\n",
        "    # overlay heatmap over rgb image\n",
        "    rgb_image = np.uint8(normalize_image(x_fullsize))\n",
        "    heatmap_arr = np.uint8(normalize_image(attributions_lgc))\n",
        "\n",
        "    # Resize heatmap if sizes are different\n",
        "    if rgb_image.shape[:2] != heatmap_arr.shape[:2]:\n",
        "        resized_heatmap = cv2.resize(heatmap_arr, (rgb_image.shape[:2][1],rgb_image.shape[:2][0]), interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "    # Apply colormap to heatmap\n",
        "    heatmap_colored = cv2.applyColorMap(np.uint8(resized_heatmap), cv2.COLORMAP_JET)\n",
        "\n",
        "    overlaid_image = normalize_image((1-alpha)*rgb_image + alpha*heatmap_colored)\n",
        "\n",
        "    return overlaid_image, pred_label_idx.cpu()"
      ],
      "metadata": {
        "id": "sPARrewPH13s"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main"
      ],
      "metadata": {
        "id": "r-H2vohEKm1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def main(model_name, model_path, images_dir, masks_dir, annotations_file, dest_folder, layer_number):\n",
        "\n",
        "    # load model\n",
        "    model_weight_path = os.path.join(model_path, 'weights.pth')\n",
        "    model_arc_path = os.path.join(model_path, 'arc.pth')\n",
        "    custom_model = TrainedModel(model_arc_path, model_weight_path, model_name)\n",
        "\n",
        "    # create dataloader\n",
        "    dataloader_norm = get_test_dataloader(images_dir, annotations_file)\n",
        "\n",
        "    img_names = []\n",
        "    class_label = []\n",
        "    y_preds = []\n",
        "    y_targets = []\n",
        "\n",
        "    # create destination folder\n",
        "    if not os.path.exists(dest_folder):\n",
        "        os.makedirs(dest_folder)\n",
        "\n",
        "    # for each test image, get prediction, if the prediction was correct and heatmap\n",
        "    for image, label, img_name in dataloader_norm:\n",
        "\n",
        "        rgb_img = find_corresponding_image(images_dir, img_name[0])\n",
        "        heatmap, y_pred = get_attention_map(model_name, custom_model, image[0], rgb_img, layer_number, 0.3)\n",
        "\n",
        "        # save targets and predictions\n",
        "        y_preds.append(y_pred)\n",
        "        img_names.append(str(img_name[0]))\n",
        "        y_targets.append(int(label[0].item()))\n",
        "\n",
        "        # create path according to prediction\n",
        "        true_class_label = class_dict[int(label[0].item())]\n",
        "        class_label.append(true_class_label)\n",
        "\n",
        "        # if the image was correctly classified\n",
        "        if label[0].item() == y_pred:\n",
        "            dest_path = os.path.join(dest_folder, 'correctly_classified', true_class_label)\n",
        "        else:\n",
        "            dest_path = os.path.join(dest_folder, 'misclassified', true_class_label, f'classified_{y_pred}')\n",
        "\n",
        "        # create directory if it doesnt exist\n",
        "        if not os.path.exists(dest_path):\n",
        "            os.makedirs(dest_path)\n",
        "\n",
        "        # get corresponding mask\n",
        "        mask = find_corresponding_mask(masks_dir, img_name[0])\n",
        "        if mask is not None:\n",
        "            # get the 1x3 plot\n",
        "            save_1_3_plot(rgb_img, heatmap, mask, img_name[0], dest_path)\n",
        "\n",
        "    # save predictions\n",
        "    csv_path = os.path.join(dest_folder, f'{model_name}_predictions.csv')\n",
        "    df = pd.DataFrame({'img_name': img_names, 'y_pred': y_preds, 'y_targets': y_targets, 'true_class': class_label})\n",
        "    df.to_csv(csv_path, index=False)\n",
        "\n",
        "    return img_name[0], true_class_label\n"
      ],
      "metadata": {
        "id": "Zay9hvO8KoWq"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### provide paths"
      ],
      "metadata": {
        "id": "wtirNnaOIwyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'resnet50'\n",
        "conv_layer_number = 34\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/CBIS-TRAINING-LOGS/patch_classifier_models/resnet50/p50_1.json/finetune/checkpoints'\n",
        "images_dir = '/content/drive/MyDrive/Colab Notebooks/images_attrib/images'\n",
        "masks_dir = '/content/drive/MyDrive/Colab Notebooks/images_attrib/masks'\n",
        "annotations_file = '/content/drive/MyDrive/Colab Notebooks/images_attrib/annotations.csv'\n",
        "dest_folder = '/content/drive/MyDrive/Colab Notebooks/Data/saved_heatmaps'"
      ],
      "metadata": {
        "id": "se5pwkvzIv9k"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SrilA8KxMe4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = main(model_name, model_path, images_dir, masks_dir, annotations_file, dest_folder, conv_layer_number)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UmuG5aGMeS2",
        "outputId": "ee6d073f-d19b-42de-9993-3370a80bac1d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 0.5757121439280359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U1t5UR9ikPD2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}